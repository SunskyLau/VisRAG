# VisRAG é¡¹ç›®è¿è¡ŒæŒ‡å—

> **é‡è¦æç¤º**ï¼šæœ¬æ–‡æ¡£å®Œå…¨åŸºäºé¡¹ç›®å®é™…ä»£ç ç¼–å†™ï¼Œæ‰€æœ‰å‘½ä»¤ã€è·¯å¾„å’Œå‚æ•°å‡æ¥è‡ªé¡¹ç›®æºä»£ç ã€‚æ–‡æ¡£å°† VisRAG å’Œ EVisRAG å®Œå…¨åˆ†å¼€è®²è§£ã€‚

## ğŸ“‹ ç›®å½•

- [ç¬¬ä¸€éƒ¨åˆ†ï¼šEVisRAG (VisRAG 2.0)](#ç¬¬ä¸€éƒ¨åˆ†evisrag-visrag-20)
  - [EVisRAG æ¦‚è¿°](#evisrag-æ¦‚è¿°)
  - [EVisRAG ç¯å¢ƒé…ç½®](#evisrag-ç¯å¢ƒé…ç½®)
  - [EVisRAG æ¨ç†å’Œè¯„ä¼°](#evisrag-æ¨ç†å’Œè¯„ä¼°)
  - [EVisRAG è®­ç»ƒ](#evisrag-è®­ç»ƒ)
- [ç¬¬äºŒéƒ¨åˆ†ï¼šVisRAG 1.0](#ç¬¬äºŒéƒ¨åˆ†visrag-10)
  - [VisRAG æ¦‚è¿°](#visrag-æ¦‚è¿°)
  - [VisRAG ç¯å¢ƒé…ç½®](#visrag-ç¯å¢ƒé…ç½®)
  - [VisRAG-Ret ä½¿ç”¨](#visrag-ret-ä½¿ç”¨)
  - [VisRAG-Ret è¯„ä¼°](#visrag-ret-è¯„ä¼°)
  - [VisRAG-Ret è®­ç»ƒ](#visrag-ret-è®­ç»ƒ)
  - [VisRAG-Gen ç”Ÿæˆ](#visrag-gen-ç”Ÿæˆ)
  - [VisRAG Pipeline æ¼”ç¤º](#visrag-pipeline-æ¼”ç¤º)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

---

# ç¬¬ä¸€éƒ¨åˆ†ï¼šEVisRAG (VisRAG 2.0)

## EVisRAG æ¦‚è¿°

**EVisRAG** æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¯æ®å¼•å¯¼è§†è§‰æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºå¤šå›¾åƒé—®ç­”ä»»åŠ¡ã€‚EVisRAG é¦–å…ˆè§‚å¯Ÿæ£€ç´¢åˆ°çš„å›¾åƒæ”¶é›†æ¯å¼ å›¾åƒçš„è¯æ®ï¼Œç„¶ååŸºäºè¿™äº›è¯æ®è¿›è¡Œæ¨ç†æ¥å›ç­”é—®é¢˜ã€‚

**é¡¹ç›®ç»“æ„**ï¼š
- `evisrag_scripts/` - EVisRAG ç›¸å…³è„šæœ¬
- `src/evisrag/` - EVisRAG æ ¸å¿ƒä»£ç 
- `src/rsgrpo/` - RS-GRPO è®­ç»ƒç®—æ³•å®ç°

---

## EVisRAG ç¯å¢ƒé…ç½®

### æ­¥éª¤ 1ï¼šå…‹éš†é¡¹ç›®

```bash
git clone https://github.com/OpenBMB/VisRAG.git
cd VisRAG
```

### æ­¥éª¤ 2ï¼šåˆ›å»º Conda ç¯å¢ƒ

```bash
conda create --name EVisRAG python==3.10
conda activate EVisRAG
```

### æ­¥éª¤ 3ï¼šå®‰è£…ä¾èµ–

```bash
pip install -r EVisRAG_requirements.txt
```

**æ³¨æ„**ï¼šæ ¹æ® `EVisRAG_requirements.txt`ï¼Œä¸»è¦ä¾èµ–åŒ…æ‹¬ï¼š
- `vllm==0.9.1` - ç”¨äºé«˜æ•ˆæ¨ç†
- `transformers==4.51.3` - Hugging Face æ¨¡å‹åº“
- `qwen-vl-utils==0.0.11` - Qwen è§†è§‰æ¨¡å‹å·¥å…·
- `flash_attn==2.7.4` - Flash Attentionï¼ˆéœ€è¦ CUDA æ”¯æŒï¼‰
- å…¶ä»–ä¾èµ–è§ `EVisRAG_requirements.txt`

### æ­¥éª¤ 4ï¼šéªŒè¯å®‰è£…

```bash
python -c "import vllm; import transformers; from qwen_vl_utils import process_vision_info; print('EVisRAG ç¯å¢ƒå®‰è£…æˆåŠŸï¼')"
```

---

## EVisRAG æ¨ç†å’Œè¯„ä¼°

### 1. å‡†å¤‡æ¨¡å‹å’Œæ•°æ®

#### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

ä» Hugging Face ä¸‹è½½æ¨¡å‹ï¼š
- EVisRAG-7B: https://huggingface.co/openbmb/EVisRAG-7B
- EVisRAG-3B: https://huggingface.co/openbmb/EVisRAG-3B

```bash
# ä½¿ç”¨ huggingface-cli ä¸‹è½½
huggingface-cli download openbmb/EVisRAG-7B --local-dir ./models/EVisRAG-7B
```

#### å‡†å¤‡æµ‹è¯•æ•°æ®

æ ¹æ® `src/evisrag/predict.py` ç¬¬ 75-76 è¡Œï¼Œæµ‹è¯•æ•°æ®åº”æ”¾åœ¨ï¼š
```
./data/EVisRAG-Test-{BENCHMARK}/top3_test.jsonl
```

æ”¯æŒçš„åŸºå‡†æµ‹è¯•ï¼ˆæ ¹æ® `src/evisrag/predict.py` ç¬¬ 18 è¡Œï¼‰ï¼š
- ChartVQA
- InfoVQA
- SlideVQA
- DocVQA
- ViDoSeek

### 2. è¿è¡Œé¢„æµ‹

#### ä¿®æ”¹æ¨¡å‹è·¯å¾„

æ ¹æ® `src/evisrag/predict.py` ç¬¬ 67-70 è¡Œï¼Œéœ€è¦ä¿®æ”¹æ¨¡å‹è·¯å¾„ï¼š

```python
elif args.model == "EVisRAG3B":
    model_path = "xxx/EVisRAG-3B"  # æ›¿æ¢ xxx/ ä¸ºå®é™…è·¯å¾„
elif args.model == "EVisRAG7B":
    model_path = "xxx/EVisRAG-7B"  # æ›¿æ¢ xxx/ ä¸ºå®é™…è·¯å¾„
```

#### è¿è¡Œé¢„æµ‹è„šæœ¬

æ ¹æ® `evisrag_scripts/predict.sh`ï¼š

```bash
python src/evisrag/predict.py \
    --benchmark DocVQA \
    --model EVisRAG7B \
    --method evidence_prompt_grpo \
    --idx 0 \
    --temperature 0.0 \
    --topk 3
```

**å‚æ•°è¯´æ˜**ï¼ˆæ ¹æ® `src/evisrag/predict.py` ç¬¬ 29-35 è¡Œï¼‰ï¼š
- `--benchmark`: åŸºå‡†æµ‹è¯•åç§°ï¼ˆChartVQA, InfoVQA, SlideVQA, DocVQA, ViDoSeekï¼‰
- `--model`: æ¨¡å‹åç§°ï¼ˆEVisRAG7B, EVisRAG3B ç­‰ï¼‰
- `--method`: æç¤ºæ–¹æ³•ï¼ˆbaseline, CCOT, COCOT, DDCOT, evidence_prompt_grpoï¼‰
- `--idx`: èµ·å§‹ç´¢å¼•ï¼ˆé»˜è®¤ -1ï¼‰
- `--temperature`: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ 0.1ï¼‰
- `--topk`: æ£€ç´¢ top-k æ–‡æ¡£ï¼ˆé»˜è®¤ 3ï¼‰

**è¾“å‡ºä½ç½®**ï¼ˆæ ¹æ® `src/evisrag/predict.py` ç¬¬ 125-126 è¡Œï¼‰ï¼š
```
./preds/{BENCHMARK}/{MODEL}_{METHOD}_{IDX}-{TOPK}.jsonl
```

### 3. è¿è¡Œè¯„ä¼°

æ ¹æ® `evisrag_scripts/eval.sh`ï¼š

```bash
python src/evisrag/eval.py \
    --benchmark SlideVQA \
    --model_tag SFT_evidence_prompt_grpo_1-3
```

**å‚æ•°è¯´æ˜**ï¼ˆæ ¹æ® `src/evisrag/eval.py` ç¬¬ 30-32 è¡Œï¼‰ï¼š
- `--benchmark`: åŸºå‡†æµ‹è¯•åç§°
- `--model_tag`: æ¨¡å‹æ ‡ç­¾ï¼Œåº”ä¸é¢„æµ‹æ–‡ä»¶ååŒ¹é…

**é¢„æµ‹æ–‡ä»¶è·¯å¾„**ï¼ˆæ ¹æ® `src/evisrag/eval.py` ç¬¬ 175 è¡Œï¼‰ï¼š
```
./preds/{BENCHMARK}/{MODEL_TAG}.jsonl
```

**è¯„ä¼°æŒ‡æ ‡**ï¼ˆæ ¹æ® `src/evisrag/eval.py` ç¬¬ 137-148 è¡Œï¼‰ï¼š
- `global_em`: å…¨å±€ç²¾ç¡®åŒ¹é…
- `global_acc`: å…¨å±€å‡†ç¡®ç‡
- `global_f1`: å…¨å±€ F1 åˆ†æ•°
- `issuff_em`: å¯å›ç­”é—®é¢˜çš„ç²¾ç¡®åŒ¹é…
- `issuff_acc`: å¯å›ç­”é—®é¢˜çš„å‡†ç¡®ç‡
- `issuff_f1`: å¯å›ç­”é—®é¢˜çš„ F1 åˆ†æ•°
- `unsuff_em`: æ— æ³•å›ç­”é—®é¢˜çš„ç²¾ç¡®åŒ¹é…

---

## EVisRAG è®­ç»ƒ

EVisRAG é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šå…ˆè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œç„¶åè¿›è¡Œ RS-GRPO å¼ºåŒ–å­¦ä¹ ã€‚

### é˜¶æ®µ 1ï¼šç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰

#### æ­¥éª¤ 1ï¼šå…‹éš† LLaMA-Factory

æ ¹æ® `README.md` ç¬¬ 98 è¡Œï¼š

```bash
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
```

#### æ­¥éª¤ 2ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®

è®­ç»ƒæ•°æ®åº”ä» Hugging Face ä¸‹è½½ï¼š`EVisRAG-Train`

#### æ­¥éª¤ 3ï¼šä¿®æ”¹è®­ç»ƒè„šæœ¬

æ ¹æ® `evisrag_scripts/full_sft.sh`ï¼Œéœ€è¦ä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š

```bash
#!/bin/bash
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

llamafactory-cli train \
    --stage sft \
    --do_train True \
    --model_name_or_path xxx/Qwen2.5-VL-7B-Instruct \  # æ›¿æ¢ xxx/ ä¸ºå®é™…è·¯å¾„
    --preprocessing_num_workers 16 \
    --finetuning_type full \
    --freeze_vision_tower true \
    --template qwen2_vl \
    --flash_attn fa2 \
    --bf16 true \
    --dataset_dir data/Train \              # ç›¸å¯¹äº LLaMA-Factory ç›®å½•
    --dataset evidencecot \
    --val_size 0.0 \
    --image_max_pixels 3920000 \
    --cutoff_len 32000 \
    --learning_rate 5e-7 \
    --num_train_epochs 1.0 \
    --max_samples 100000 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 8 \
    --lr_scheduler_type cosine \
    --max_grad_norm 1.0 \
    --logging_steps 5 \
    --save_steps 100 \
    --warmup_steps 200 \
    --packing False \
    --output_dir xxx/Qwen7B-SFT \    # æ›¿æ¢ xxx/ ä¸ºå®é™…è·¯å¾„
    --bf16 True \
    --plot_loss True \
    --trust_remote_code True \
    --ddp_timeout 180000000 \
    --include_num_input_tokens_seen True \
    --optim adamw_torch \
    --deepspeed config/ds_z3_config.json \  # ç›¸å¯¹äº LLaMA-Factory ç›®å½•
    --report_to tensorboard > sft.log 2>&1
```

**æ³¨æ„**ï¼š
- DeepSpeed é…ç½®æ–‡ä»¶è·¯å¾„ï¼š`config/ds_z3_config.json`ï¼ˆç›¸å¯¹äº LLaMA-Factory ç›®å½•ï¼‰
- æ•°æ®é›†è·¯å¾„ï¼š`data/Train`ï¼ˆç›¸å¯¹äº LLaMA-Factory ç›®å½•ï¼‰

#### æ­¥éª¤ 4ï¼šè¿è¡Œè®­ç»ƒ

```bash
bash ../evisrag_scripts/full_sft.sh
```

### é˜¶æ®µ 2ï¼šRS-GRPO è®­ç»ƒ

#### æ­¥éª¤ 1ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®

æ ¹æ® `evisrag_scripts/run_rsgrpo.sh` ç¬¬ 16-17 è¡Œï¼Œéœ€è¦ä»¥ä¸‹æ–‡ä»¶ï¼š
- `../../data/Train/evidencecot_GRPO.jsonl`ï¼ˆè®­ç»ƒæ•°æ®ï¼‰
- `../../data/Train/test_GRPO.jsonl`ï¼ˆéªŒè¯æ•°æ®ï¼‰

#### æ­¥éª¤ 2ï¼šä¿®æ”¹è®­ç»ƒè„šæœ¬

æ ¹æ® `evisrag_scripts/run_rsgrpo.sh`ï¼š

```bash
#!/bin/bash

cd src/rsgrpo

set -x

export PYTHONUNBUFFERED=1
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  # æ ¹æ®å®é™… GPU æ•°é‡è°ƒæ•´
export VLLM_ATTENTION_BACKEND=XFORMERS
export VLLM_USE_V1=0

MODEL_PATH=xxx/Qwen7B-SFT  # æ›¿æ¢ xxx/ ä¸º SFT é˜¶æ®µçš„è¾“å‡ºè·¯å¾„

python3 -m verl.trainer.main \
    config=examples/config.yaml \
    data.train_files="../../data/Train/evidencecot_GRPO.jsonl" \
    data.val_files="../../data/Train/test_GRPO.jsonl" \
    data.rollout_batch_size=32 \
    worker.rollout.enable_chunked_prefill=false \
    worker.actor.model.model_path=${MODEL_PATH} \
    worker.rollout.limit_images=5 \
    trainer.experiment_name=EVisRAG7B \
    trainer.n_gpus_per_node=8  # æ ¹æ®å®é™… GPU æ•°é‡è°ƒæ•´
```

**æ³¨æ„**ï¼š
- é…ç½®æ–‡ä»¶è·¯å¾„ï¼š`src/rsgrpo/examples/config.yaml`
- è®­ç»ƒæ•°æ®è·¯å¾„ï¼šç›¸å¯¹äº `src/rsgrpo/` ç›®å½•

#### æ­¥éª¤ 3ï¼šè¿è¡Œè®­ç»ƒ

```bash
bash evisrag_scripts/run_rsgrpo.sh
```

---

# ç¬¬äºŒéƒ¨åˆ†ï¼šVisRAG 1.0

## VisRAG æ¦‚è¿°

**VisRAG** æ˜¯ä¸€ä¸ªåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚VisRAG åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š
- **VisRAG-Ret**ï¼šæ–‡æ¡£æ£€ç´¢æ¨¡å‹ï¼ŒåŸºäº MiniCPM-V 2.0
- **VisRAG-Gen**ï¼šç”Ÿæˆæ¨¡å‹ï¼Œå¯ä½¿ç”¨ä»»æ„ VLMï¼ˆå¦‚ MiniCPM-V 2.0, MiniCPM-V 2.6, GPT-4o ç­‰ï¼‰

**é¡¹ç›®ç»“æ„**ï¼š
- `visrag_scripts/` - VisRAG ç›¸å…³è„šæœ¬
  - `train_retriever/` - VisRAG-Ret è®­ç»ƒè„šæœ¬
  - `eval_retriever/` - VisRAG-Ret è¯„ä¼°è„šæœ¬
  - `generate/` - VisRAG-Gen ç”Ÿæˆè„šæœ¬
  - `demo/visrag_pipeline/` - VisRAG Pipeline æ¼”ç¤º
- `src/openmatch/` - VisRAG-Ret æ ¸å¿ƒä»£ç ï¼ˆåŸºäº OpenMatchï¼‰

---

## VisRAG ç¯å¢ƒé…ç½®

### æ­¥éª¤ 1ï¼šå…‹éš†é¡¹ç›®

```bash
git clone https://github.com/OpenBMB/VisRAG.git
cd VisRAG
```

### æ­¥éª¤ 2ï¼šåˆ›å»º Conda ç¯å¢ƒ

```bash
conda create --name VisRAG python==3.10.8
conda activate VisRAG
```

### æ­¥éª¤ 3ï¼šå®‰è£… CUDA å·¥å…·åŒ…

æ ¹æ® `README.md` ç¬¬ 77 è¡Œï¼š

```bash
conda install nvidia/label/cuda-11.8.0::cuda-toolkit
```

### æ­¥éª¤ 4ï¼šå®‰è£…é¡¹ç›®ä¾èµ–

æ ¹æ® `README.md` ç¬¬ 79-83 è¡Œï¼š

```bash
pip install -r requirements.txt
pip install -e .
cd timm_modified
pip install -e .
cd ..
```

**æ³¨æ„**ï¼šæ ¹æ® `README.md` ç¬¬ 86 è¡Œï¼Œ`timm_modified` æ˜¯æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹çš„å¢å¼ºç‰ˆ timm åº“ã€‚

### æ­¥éª¤ 5ï¼šéªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

---

## VisRAG-Ret ä½¿ç”¨

### åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

æ ¹æ® `README.md` ç¬¬ 272-329 è¡Œï¼Œä»¥ä¸‹æ˜¯ VisRAG-Ret çš„ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from transformers import AutoModel, AutoTokenizer
import torch
import torch.nn.functional as F
from PIL import Image
import os

def weighted_mean_pooling(hidden, attention_mask):
    attention_mask_ = attention_mask * attention_mask.cumsum(dim=1)
    s = torch.sum(hidden * attention_mask_.unsqueeze(-1).float(), dim=1)
    d = attention_mask_.sum(dim=1, keepdim=True).float()
    reps = s / d
    return reps

@torch.no_grad()
def encode(text_or_image_list, model, tokenizer):
    if isinstance(text_or_image_list[0], str):
        inputs = {
            "text": text_or_image_list,
            'image': [None] * len(text_or_image_list),
            'tokenizer': tokenizer
        }
    else:
        inputs = {
            "text": [''] * len(text_or_image_list),
            'image': text_or_image_list,
            'tokenizer': tokenizer
        }
    outputs = model(**inputs)
    attention_mask = outputs.attention_mask
    hidden = outputs.last_hidden_state
    
    reps = weighted_mean_pooling(hidden, attention_mask)   
    embeddings = F.normalize(reps, p=2, dim=1).detach().cpu().numpy()
    return embeddings

# åŠ è½½æ¨¡å‹
model_name_or_path = "openbmb/VisRAG-Ret"
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16, trust_remote_code=True)
model.eval()

# å‡†å¤‡æŸ¥è¯¢å’Œæ–‡æ¡£
queries = ["What does a dog look like?"]
passages = [
    Image.open('test_image/cat.jpeg').convert('RGB'),
    Image.open('test_image/dog.jpg').convert('RGB'),
]

# æ·»åŠ æŒ‡ä»¤å‰ç¼€
INSTRUCTION = "Represent this query for retrieving relevant documents: "
queries = [INSTRUCTION + query for query in queries]

# ç¼–ç 
embeddings_query = encode(queries, model, tokenizer)
embeddings_doc = encode(passages, model, tokenizer)

# è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
scores = (embeddings_query @ embeddings_doc.T)
print(scores.tolist())
```

---

## VisRAG-Ret è¯„ä¼°

### è¿è¡Œè¯„ä¼°è„šæœ¬

æ ¹æ® `visrag_scripts/eval_retriever/eval.sh` å’Œ `README.md` ç¬¬ 146 è¡Œï¼š

```bash
bash visrag_scripts/eval_retriever/eval.sh \
    512 \                    # MAX_Q_LEN (æŸ¥è¯¢æœ€å¤§é•¿åº¦)
    2048 \                   # MAX_P_LEN (æ–‡æ¡£æœ€å¤§é•¿åº¦)
    16 \                     # PER_DEV_BATCH_SIZE (æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°)
    8 \                      # GPUS_PER_NODE (æ¯ä¸ªèŠ‚ç‚¹çš„GPUæ•°é‡)
    wmean \                  # POOLING (æ± åŒ–æ–¹æ³•)
    causal \                 # ATTENTION (æ³¨æ„åŠ›ç±»å‹)
    ArxivQA,ChartQA,MP-DocVQA,InfoVQA,PlotQA,SlideVQA \  # SUB_DATASET (æ•°æ®é›†åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”)
    <ckpt_path>             # MODEL_PATH (æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„)
```

**å‚æ•°è¯´æ˜**ï¼ˆæ ¹æ® `visrag_scripts/eval_retriever/eval.sh` ç¬¬ 2-9 è¡Œï¼‰ï¼š
- `MAX_Q_LEN`: æŸ¥è¯¢æœ€å¤§é•¿åº¦
- `MAX_P_LEN`: æ–‡æ¡£æœ€å¤§é•¿åº¦
- `PER_DEV_BATCH_SIZE`: æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°
- `GPUS_PER_NODE`: æ¯ä¸ªèŠ‚ç‚¹çš„ GPU æ•°é‡
- `POOLING`: æ± åŒ–æ–¹æ³•ï¼ˆwmean è¡¨ç¤ºåŠ æƒå¹³å‡ï¼‰
- `ATTENTION`: æ³¨æ„åŠ›ç±»å‹ï¼ˆcausal è¡¨ç¤ºå› æœæ³¨æ„åŠ›ï¼‰
- `SUB_DATASET`: æ•°æ®é›†åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”
- `MODEL_PATH`: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„

**æ•°æ®é›†è·¯å¾„**ï¼ˆæ ¹æ® `visrag_scripts/eval_retriever/eval.sh` ç¬¬ 37-39 è¡Œï¼‰ï¼š
- é»˜è®¤ä½¿ç”¨ Hugging Face ä»“åº“ï¼š`openbmb/VisRAG-Ret-Test-${SUB_DATASET}`
- å¦‚éœ€ä½¿ç”¨æœ¬åœ°æ•°æ®é›†ï¼Œéœ€ä¿®æ”¹è„šæœ¬ä¸­çš„ `CORPUS_PATH`ã€`QUERY_PATH`ã€`QRELS_PATH` å˜é‡

**è¾“å‡ºç›®å½•**ï¼ˆæ ¹æ® `visrag_scripts/eval_retriever/eval.sh` ç¬¬ 22-25 è¡Œï¼‰ï¼š
```
/data/checkpoints/eval-{TIMESTAMP}-maxq-{MAX_Q_LEN}-maxp-{MAX_P_LEN}-bsz-{PER_DEV_BATCH_SIZE}-pooling-{POOLING}-attention-{ATTENTION}-gpus-per-node-{GPUS_PER_NODE}/{SUB_DATASET}/
```

---

## VisRAG-Ret è®­ç»ƒ

### è¿è¡Œè®­ç»ƒè„šæœ¬

æ ¹æ® `visrag_scripts/train_retriever/train.sh` å’Œ `README.md` ç¬¬ 118 è¡Œï¼š

```bash
bash visrag_scripts/train_retriever/train.sh \
    2048 \                              # MAX_SEQ_LEN (æœ€å¤§åºåˆ—é•¿åº¦)
    16 \                                # PER_DEV_BATCH_SIZE (æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°)
    8 \                                 # GPUS_PER_NODE (æ¯ä¸ªèŠ‚ç‚¹çš„GPUæ•°é‡)
    0.02 \                              # SOFTMAX_TEMPERATURE (Softmaxæ¸©åº¦å‚æ•°)
    1 \                                 # EPOCH (è®­ç»ƒè½®æ•°)
    true \                              # QUERY_INSTRUCTION (æ˜¯å¦ä¸ºæŸ¥è¯¢æ·»åŠ æŒ‡ä»¤å‰ç¼€)
    false \                             # CORPUS_INSTRUCTION (æ˜¯å¦ä¸ºè¯­æ–™åº“æ·»åŠ æŒ‡ä»¤å‰ç¼€)
    config/deepspeed.json \             # DEEPSPEED_CONFIG (DeepSpeedé…ç½®æ–‡ä»¶è·¯å¾„)
    1e-5 \                              # LEARNING_RATE (å­¦ä¹ ç‡)
    false \                             # MAPPING (æ˜¯å¦ä½¿ç”¨æ˜ å°„æ•°æ®é›†)
    wmean \                             # POOLING (æ± åŒ–æ–¹æ³•)
    causal \                            # ATTENTION (æ³¨æ„åŠ›ç±»å‹)
    1 \                                 # NPASSAGE (æ¯ä¸ªæŸ¥è¯¢çš„æ–‡æ¡£æ•°é‡)
    true \                              # GRADCACHE (æ˜¯å¦å¯ç”¨æ¢¯åº¦ç¼“å­˜)
    2 \                                 # GRADCACHE_MICRO (æ¢¯åº¦ç¼“å­˜çš„å¾®æ‰¹æ¬¡å¤§å°)
    false \                             # PASSAGE_STOP_GRAD (æ˜¯å¦åœæ­¢æ–‡æ¡£çš„æ¢¯åº¦)
    <model_dir> \                       # MODEL_PATH (åŸºç¡€æ¨¡å‹è·¯å¾„)
    <repo_name_or_path>                 # DATASET_PATH (æ•°æ®é›†è·¯å¾„)
```

**å‚æ•°è¯´æ˜**ï¼ˆæ ¹æ® `visrag_scripts/train_retriever/train.sh` ç¬¬ 6-23 è¡Œï¼‰ï¼š
- å‚æ•°é¡ºåºå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°é¡ºåºä¼ é€’
- `DATASET_PATH` å¯ä»¥æ˜¯ï¼š
  - Hugging Face ä»“åº“ï¼š`openbmb/VisRAG-Ret-Train-In-domain-data` æˆ– `openbmb/VisRAG-Ret-Train-Synthetic-data`
  - æœ¬åœ°æ•°æ®é›†ç›®å½•è·¯å¾„

**æ³¨æ„äº‹é¡¹**ï¼ˆæ ¹æ® `README.md` ç¬¬ 120-125 è¡Œï¼‰ï¼š
1. è®­ç»ƒæ•°æ®åœ¨ Hugging Face çš„ `VisRAG` Collection ä¸­
2. `In-domain-data` å’Œ `Synthetic-data` æ˜¯åˆ†å¼€çš„ï¼Œå¦‚éœ€ä½¿ç”¨å®Œæ•´æ•°æ®é›†ï¼Œéœ€è¦æ‰‹åŠ¨åˆå¹¶å’Œæ‰“ä¹±
3. å¦‚æœä½¿ç”¨æœ¬åœ°æ•°æ®é›†ï¼Œéœ€è¦ä»è®­ç»ƒè„šæœ¬ä¸­åˆ é™¤ `--from_hf_repo` å‚æ•°
4. æœ¬åœ°æ•°æ®é›†ç›®å½•å¿…é¡»åŒ…å« `metadata.json` æ–‡ä»¶ï¼Œå…¶ä¸­å¿…é¡»åŒ…å« `length` å­—æ®µæŒ‡å®šæ ·æœ¬æ€»æ•°

---

## VisRAG-Gen ç”Ÿæˆ

### è¿è¡Œç”Ÿæˆè„šæœ¬

æ ¹æ® `visrag_scripts/generate/generate.py` å’Œ `README.md` ç¬¬ 157-169 è¡Œï¼š

```bash
python visrag_scripts/generate/generate.py \
    --model_name MiniCPMV2.0 \                    # æ¨¡å‹åç§° (MiniCPM, MiniCPMV2.0, MiniCPMV2.6, gpt4o)
    --model_name_or_path <model_path> \           # æ¨¡å‹è·¯å¾„
    --dataset_name DocVQA \                       # æ•°æ®é›†åç§° (ArxivQA, ChartQA, PlotQA, MP-DocVQA, SlideVQA, InfoVQA)
    --dataset_name_or_path <dataset_path> \       # æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä» HF åŠ è½½ï¼‰
    --rank 0 \                                    # è¿›ç¨‹æ’å
    --world_size 1 \                              # æ€»è¿›ç¨‹æ•°
    --topk 3 \                                    # æ£€ç´¢æ–‡æ¡£æ•°é‡
    --results_root_dir ./retrieval_results/ \     # æ£€ç´¢ç»“æœç›®å½•
    --task_type multi_image \                     # ä»»åŠ¡ç±»å‹ (text, page_concatenation, weighted_selection, multi_image)
    --concatenate_type horizontal \                # æ‹¼æ¥ç±»å‹ï¼ˆä»… page_concatenation éœ€è¦ï¼Œhorizontal æˆ– verticalï¼‰
    --output_dir ./generation_results/             # è¾“å‡ºç›®å½•
```

**å‚æ•°è¯´æ˜**ï¼ˆæ ¹æ® `visrag_scripts/generate/generate.py` ç¬¬ 27-42 è¡Œï¼‰ï¼š
- `--model_name`: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼ï¼šMiniCPM, MiniCPMV2.0, MiniCPMV2.6, gpt4o
- `--dataset_name`: æ•°æ®é›†åç§°ï¼Œå¯é€‰å€¼ï¼šArxivQA, ChartQA, PlotQA, MP-DocVQA, SlideVQA, InfoVQA
- `--task_type`: ä»»åŠ¡ç±»å‹
  - `text`: æ–‡æœ¬ç”Ÿæˆ
  - `page_concatenation`: é¡µé¢æ‹¼æ¥
  - `weighted_selection`: åŠ æƒé€‰æ‹©
  - `multi_image`: å¤šå›¾åƒç”Ÿæˆ
- `--concatenate_type`: ä»…åœ¨ `task_type=page_concatenation` æ—¶éœ€è¦
- `--use_positive_sample`: å¦‚æœå¯ç”¨ï¼Œåªä½¿ç”¨æ­£æ ·æœ¬ï¼Œå¿½ç•¥æ£€ç´¢ç»“æœ
- `--openai_api_key`: ä»…åœ¨ `model_name=gpt4o` æ—¶éœ€è¦

**æ£€ç´¢ç»“æœæ ¼å¼**ï¼ˆæ ¹æ® `README.md` ç¬¬ 171 è¡Œï¼‰ï¼š
- æ£€ç´¢ç»“æœåº”ä¿å­˜åœ¨ `results_root_dir/dataset_name/*.trec` æ ¼å¼

---

## VisRAG Pipeline æ¼”ç¤º

### è¿è¡Œ Pipeline

æ ¹æ® `visrag_scripts/demo/visrag_pipeline/README.md`ï¼š

#### æ­¥éª¤ 1ï¼šæ„å»ºç´¢å¼•

```bash
cd visrag_scripts/demo/visrag_pipeline
python build_index.py
```

è„šæœ¬ä¼šæç¤ºè¾“å…¥ï¼š
- PDF æ–‡ä»¶ç›®å½•è·¯å¾„
- çŸ¥è¯†åº“ç´¢å¼•å­˜å‚¨è·¯å¾„

**æ³¨æ„**ï¼šæ ¹æ® `visrag_scripts/demo/visrag_pipeline/build_index.py` ç¬¬ 62 è¡Œï¼Œä½¿ç”¨çš„æ¨¡å‹æ˜¯ `openbmb/VisRAG-Ret`ã€‚

#### æ­¥éª¤ 2ï¼šæŸ¥è¯¢çŸ¥è¯†åº“

```bash
python answer.py
```

è„šæœ¬ä¼šæç¤ºè¾“å…¥ï¼š
- çŸ¥è¯†åº“è·¯å¾„
- æŸ¥è¯¢é—®é¢˜
- æ£€ç´¢æ–‡æ¡£æ•°é‡

**æ³¨æ„**ï¼š
- æ ¹æ® `visrag_scripts/demo/visrag_pipeline/answer.py` ç¬¬ 56-57 è¡Œï¼Œä½¿ç”¨çš„æ¨¡å‹æ˜¯ï¼š
  - VisRAG-Ret: `openbmb/VisRAG-Ret`
  - VisRAG-Gen: `openbmb/MiniCPM-V-2_6`
- æ ¹æ® `README.md` ç¬¬ 7 è¡Œï¼Œè¿è¡Œå®Œæ•´ pipeline éœ€è¦çº¦ 40GB GPU å†…å­˜

---

## å¸¸è§é—®é¢˜

### EVisRAG ç›¸å…³é—®é¢˜

1. **CUDA å†…å­˜ä¸è¶³**
   - å‡å° `batch_size` æˆ–ä½¿ç”¨æ›´å°‘çš„ GPU
   - æ ¹æ® `src/evisrag/predict.py` ç¬¬ 114 è¡Œï¼Œå¯ä»¥è°ƒæ•´ `tensor_parallel_size`

2. **æ¨¡å‹è·¯å¾„é”™è¯¯**
   - ç¡®ä¿ä¿®æ”¹ `src/evisrag/predict.py` ç¬¬ 67-70 è¡Œçš„æ¨¡å‹è·¯å¾„ï¼Œå°† `xxx/` æ›¿æ¢ä¸ºå®é™…è·¯å¾„

3. **æ•°æ®è·¯å¾„é”™è¯¯**
   - ç¡®ä¿æµ‹è¯•æ•°æ®æ”¾åœ¨ `./data/EVisRAG-Test-{BENCHMARK}/top3_test.jsonl`

### VisRAG ç›¸å…³é—®é¢˜

1. **CUDA ç‰ˆæœ¬ä¸åŒ¹é…**
   - ç¡®ä¿å®‰è£… CUDA 11.8ï¼ˆæ ¹æ® `README.md` ç¬¬ 77 è¡Œï¼‰

2. **timm_modified å®‰è£…å¤±è´¥**
   - ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œ `cd timm_modified && pip install -e .`

3. **è®­ç»ƒæ•°æ®æ ¼å¼é”™è¯¯**
   - ç¡®ä¿æœ¬åœ°æ•°æ®é›†åŒ…å« `metadata.json` æ–‡ä»¶ï¼Œä¸”åŒ…å« `length` å­—æ®µ

---

## å‚è€ƒèµ„æ–™

### å®˜æ–¹èµ„æº

- **GitHub ä»“åº“**ï¼šhttps://github.com/OpenBMB/VisRAG
- **EVisRAG è®ºæ–‡**ï¼šhttps://arxiv.org/abs/2510.09733
- **VisRAG è®ºæ–‡**ï¼šhttps://arxiv.org/abs/2410.10594

### æ¨¡å‹å’Œæ•°æ®é›†

- **EVisRAG-7B**ï¼šhttps://huggingface.co/openbmb/EVisRAG-7B
- **EVisRAG-3B**ï¼šhttps://huggingface.co/openbmb/EVisRAG-3B
- **VisRAG-Ret**ï¼šhttps://huggingface.co/openbmb/VisRAG-Ret
- **æ•°æ®é›†é›†åˆ**ï¼šhttps://huggingface.co/collections/openbmb/visrag-6717bbfb471bb018a49f1c69

### ç›¸å…³é¡¹ç›®

- **LLaMA-Factory**ï¼šhttps://github.com/hiyouga/LLaMA-Factoryï¼ˆEVisRAG SFT é˜¶æ®µï¼‰
- **Easy-R1**ï¼šhttps://github.com/hiyouga/EasyR1ï¼ˆRS-GRPO åŸºç¡€ï¼‰
- **OpenMatch**ï¼šhttps://github.com/OpenMatch/OpenMatchï¼ˆVisRAG-Ret è®­ç»ƒæ¡†æ¶ï¼‰

### æŠ€æœ¯æ”¯æŒ

- **EVisRAG**ï¼š
  - Yubo Sun: syb2000417@stu.pku.edu.cn
  - Chunyi Peng: hm.cypeng@gmail.com
- **VisRAG**ï¼š
  - Shi Yu: yus21@mails.tsinghua.edu.cn
  - Chaoyue Tang: tcy006@gmail.com

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šåŸºäºé¡¹ç›®ä»£ç  2025-01-XX

**é‡è¦æç¤º**ï¼šæœ¬æ–‡æ¡£å®Œå…¨åŸºäºé¡¹ç›®å®é™…ä»£ç ç¼–å†™ï¼Œæ‰€æœ‰å‘½ä»¤ã€è·¯å¾„å’Œå‚æ•°å‡æ¥è‡ªæºä»£ç ã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒé¡¹ç›®æºä»£ç æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚
